# RLM Orchestrator Configuration Example
#
# Copy this file to config.toml and customize for your environment.
#
# IMPORTANT: Use LiteLLM gateway with DeepSeek models for best results.
# Do NOT use local Ollama models - they are not capable enough.

max_iterations = 20
max_sub_calls = 50
output_limit = 10000

# Smart bypass: skip RLM for small contexts and send directly to LLM
# Disable for testing to ensure RLM is always used
bypass_enabled = false
bypass_threshold = 0

# WASM execution configuration
[wasm]
enabled = true                  # Enable WASM features (wasm, wasm_wat commands)
rust_wasm_enabled = true        # Enable rust_wasm command (requires rustc + wasm target)
fuel_limit = 1000000            # Max WASM instructions (prevents infinite loops)
memory_limit = 67108864         # Max WASM memory in bytes (64MB)
cache_size = 100                # Max modules in memory cache

# Two-LLM code generation via LiteLLM (REQUIRED for rust_wasm_intent)
# Uses DeepSeek-coder through LiteLLM gateway to generate safe Rust code
codegen_provider = "litellm"
codegen_url = "http://localhost:4000"
codegen_model = "deepseek/deepseek-coder"

# ============================================================================
# LLM Provider Configuration
# ============================================================================
# Use LiteLLM gateway to access DeepSeek models.
# Requires LITELLM_MASTER_KEY environment variable.

# Primary provider via LiteLLM (RECOMMENDED)
[[providers]]
provider_type = "litellm"
base_url = "http://localhost:4000"
model = "deepseek/deepseek-coder"
role = "both"  # Use for both root and sub calls
weight = 1

# ============================================================================
# Alternative Configurations (NOT RECOMMENDED)
# ============================================================================

# Option: DeepSeek API directly (bypass LiteLLM)
# Requires DEEPSEEK_API_KEY environment variable
# [[providers]]
# provider_type = "deepseek"
# base_url = "https://api.deepseek.com"
# model = "deepseek-chat"
# role = "root"
# weight = 1
