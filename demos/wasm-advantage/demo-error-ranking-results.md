# Error Ranking Demo Results

This demo compares RLM performance on a complex analytical query using different LLM backends.

**Query:** "rank the errors from most often to least often found in the logs"

**Log file:** `sample.log` (9,701 chars, 117 lines)

## Results Comparison

| Metric | llama3.2:3b (Ollama) | DeepSeek (LiteLLM) |
|--------|----------------------|--------------------|
| Iterations | 20 (no answer) | 4 âœ“ |
| Total Time | ~6 min | **44 sec** |
| Tokens | 67,600 | 13,250 |
| WASM used | No | Yes |
| Success | âŒ | âœ… |

## DeepSeek Output

```
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  RLM CLI - Recursive Language Model Query                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  File:   ../demos/wasm-advantage/sample.log
â”‚  Size:   9701 chars (117 lines, ~2425 tokens)
â”‚  Model:  deepseek/deepseek-chat (via LiteLLM @ http://localhost:4000)
â”‚  Query:  rank the errors from most often to least often ...
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

Starting RLM processing...

â”Œâ”€ Iteration 1
â”‚ â³ Calling LLM...                              â”‚ â±  LLM: 4426ms
â”‚ â—€ Exec: 0ms
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
â”Œâ”€ Iteration 2
â”‚ â³ Calling LLM...                              â”‚ â±  LLM: 17808ms
â”‚ ğŸ”§ Compiling WASM... done (713ms)
â”‚ â—€ Exec: 721ms
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
â”Œâ”€ Iteration 3
â”‚ â³ Calling LLM...                              â”‚ â±  LLM: 16607ms
â”‚ ğŸ”§ Compiling WASM...â”‚ â—€ Exec: 10ms
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
â”Œâ”€ Iteration 4
â”‚ â³ Calling LLM...                              â”‚ â±  LLM: 3825ms
â”‚ â—€ Exec: 0ms
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
âœ“ Final: Error Type Rankings (most to least frequent):
============================================
1. Authen
Completed in 4 iteration(s)


â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚  Results                                                     â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  Iterations:     4
â”‚  Sub-LM calls:   0
â”‚  Tokens used:    11972 prompt + 1278 completion
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

Answer:
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
Error Type Rankings (most to least frequent):
============================================
1. AuthenticationFailed: 13 occurrences
2. RequestFailed: 11 occurrences
3. ConnectionTimeout: 10 occurrences
4. ValidationError: 9 occurrences
5. OtherError: 8 occurrences

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
```

**Total time:** 44.331 seconds

## Command Used

```bash
cargo run --release --bin rlm -- \
    ../demos/wasm-advantage/sample.log \
    "rank the errors from most often to least often found in the logs" \
    --litellm \
    --litellm-url http://localhost:4000 \
    --litellm-key $LITELLM_KEY \
    -m deepseek/deepseek-chat \
    -v
```

## Key Observations

1. **Model capability matters**: DeepSeek immediately understood to use `rust_wasm` for counting and categorizing, while llama3.2:3b struggled with the analytical query.

2. **WASM advantage**: DeepSeek compiled custom Rust code to count error types in a single pass, taking 713ms to compile and 721ms to execute.

3. **Token efficiency**: DeepSeek used ~5x fewer tokens by solving the problem in fewer iterations.

4. **Real-time progress**: The `-v` flag shows LLM calls and WASM compilation as they happen, providing visibility during the ~44 second run.
